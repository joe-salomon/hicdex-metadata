{"__version": 1, "token_id": 536669, "symbol": "OBJKT", "name": "alien_selfportrait1", "description": "The VQGAN (Vector Quantized Generative Adversarial Network) an imager via neural network itself, combined with CLIP (Contrastive Language Image Pre-training) metric, allows images to be generated based on how closely they match the entered indication. Based on the quantitative output of CLIP, the feedback is used to calculate how VQGAN can bring an image closer to the given indication. The process is repeated the number of interactions assigned.", "artifact_uri": "ipfs://QmPAEhqdy6tNn1EjPhNrn4JzQQZf2MUJyYddudV1eAEo8Q", "display_uri": "ipfs://Qmdp4e7YJN2kMGyJ45Yo2ABo7Wx69AY2Cw8QQmM6dwdBdV", "thumbnail_uri": "ipfs://QmNrhZHUaEqxhyLfqoq1mtHSipkWHeT31LNHb1QEbDHgnc", "formats": [{"uri": "ipfs://QmPAEhqdy6tNn1EjPhNrn4JzQQZf2MUJyYddudV1eAEo8Q", "mimeType": "video/mp4"}], "creators": ["tz1Mjd2jiXi4xxCNenLxCu7N29DhwYGKGi3h"], "tags": ["generativeart", "digitalart", "neuralnetworks", "glitchart", "vqgan+clip", "artificialintelligence", "newmediaart", "codeart", "machinelearning", "aigenerated"], "extra": {}}